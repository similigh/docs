---
title: Gemini Integration
description: Google Gemini API integration details
---

# Gemini Integration

How Simili Bot uses Google Gemini for AI analysis.

## Services

Simili Bot uses Gemini for:

1. **Text Embeddings** - Convert text to vectors
2. **LLM Analysis** - AI reasoning and classification

## Embeddings

### text-embedding-004

Default embedding model:

```
Input: Text string (up to ~4000 tokens)
Output: 768-dimensional vector
Speed: 100-500ms per request
Batch Size: Up to 100 texts
```

**Use Cases:**
- Convert issue text to vector for similarity search
- Generate embeddings for all issues during indexing

**Cost:** ~$0.025 per million input tokens

## LLM Analysis

Uses Gemini for analysis tasks:

### 1. Duplicate Detection
```
Input: Current issue + similar issues
Task: Determine if duplicates
Output: Boolean + confidence (0.0-1.0)
Speed: 2-5 seconds
```

### 2. Quality Assessment
```
Input: Issue title + body
Task: Evaluate description quality
Output: Score (0-100) + suggestions
Speed: 1-3 seconds
```

### 3. Issue Routing
```
Input: Issue + repository descriptions
Task: Determine correct repository
Output: Target repo name
Speed: 2-5 seconds
```

### 4. Auto Triage
```
Input: Issue content + available labels
Task: Suggest appropriate labels
Output: Labels + confidence scores
Speed: 1-2 seconds
```

## Models

Currently supports:
- `text-embedding-004` - Embeddings (default, recommended)

Other models can be added in future versions.

## Configuration

```yaml
embedding:
  provider: "gemini"
  api_key: "${GEMINI_API_KEY}"
  model: "text-embedding-004"
  dimensions: 768
  batch_size: 100
```

## API Quotas

Free Tier:
- Embeddings: 50 requests/minute
- LLM Calls: 15 requests/minute
- Generous monthly limits

Paid:
- Pay-as-you-go
- Higher quotas available

## Error Handling

Graceful degradation if Gemini unavailable:

```
If embeddings fail:
  → Step skipped
  → No similarity search
  → Continue with other analysis

If LLM fails:
  → That analysis step skipped
  → Other steps continue
  → Error logged
```

## Performance

Typical latencies:
- Embedding request: 200-500ms
- LLM analysis: 2-5 seconds
- Batch embedding: 500ms-2s

Bottleneck is usually external API calls.

## Cost Estimation

For 1,000 issues:
- Embeddings: ~$0.01-0.05 (bulk indexing)
- LLM analysis: $0.10-0.50 per issue (depends on features)
- Typical total: $100-500/month for active repo

Optimize by:
- Disabling unnecessary features
- Using `similarity-only` workflow
- Archiving old issues
- Batching operations

## Next Steps

<CardGroup cols={2}>
  <Card title="Gemini Configuration" href="/configuration/gemini">
    Setup Gemini for Simili Bot
  </Card>
  <Card title="Integrations" href="/reference/integrations">
    Other integrations
  </Card>
</CardGroup>
